{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.applications import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/' # root\n",
    "CSV_PATH = os.path.join(PATH,'csv') # folder with csv datasets\n",
    "DICOM_PATH = os.path.join(PATH, 'pool') # folder containing all of the dicom files\n",
    "JPG_PATH = os.path.join(PATH, 'pool_jpg') # folder containing all the converted jpg files\n",
    "DESTINATION_PATH = os.path.join(PATH, 'sorted_balanced') # Folder where the train and test subsets will be located\n",
    "MODELS_PATH = os.path.join(PATH,'model')\n",
    "\n",
    "# Train folder\n",
    "TRAIN_PATH = os.path.join(DESTINATION_PATH, 'train')\n",
    "TRAIN_NORMAL_PATH = os.path.join(TRAIN_PATH, 'normal')\n",
    "TRAIN_NNNP_PATH = os.path.join(TRAIN_PATH, 'nnnp')\n",
    "TRAIN_PNEUMONIA_PATH = os.path.join(TRAIN_PATH, 'pneumonia')\n",
    "\n",
    "# Validation folder\n",
    "VAL_PATH = os.path.join(DESTINATION_PATH, 'validation')\n",
    "VAL_NORMAL_PATH = os.path.join(VAL_PATH, 'normal')\n",
    "VAL_NNNP_PATH = os.path.join(VAL_PATH, 'nnnp')\n",
    "VAL_PNEUMONIA_PATH = os.path.join(VAL_PATH, 'pneumonia')\n",
    "\n",
    "# Test folder\n",
    "TEST_PATH = os.path.join(DESTINATION_PATH, 'test')\n",
    "TEST_NORMAL_PATH = os.path.join(TEST_PATH, 'normal') \n",
    "TEST_NNNP_PATH = os.path.join(TEST_PATH, 'nnnp')\n",
    "TEST_PNEUMONIA_PATH = os.path.join(TEST_PATH, 'pneumonia') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining constants and variables\n",
    "img_width, img_height = 128, 128\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "test_data_dir = \"data/test\"\n",
    "NB = 2\n",
    "BS = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = len(list(paths.list_images(TRAIN_PATH)))\n",
    "VAL = len(list(paths.list_images(VAL_PATH)))\n",
    "TEST = len(list(paths.list_images(TEST_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8416 images belonging to 2 classes.\n",
      "Found 1804 images belonging to 2 classes.\n",
      "Found 1804 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainAug = ImageDataGenerator(rescale = 1./255,\n",
    "                    fill_mode = \"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator(rescale = 1./255,\n",
    "                            fill_mode = \"nearest\")\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "                    TRAIN_PATH,\n",
    "                    target_size = (img_height, img_width),\n",
    "                    batch_size = BS,\n",
    "                    shuffle = True,\n",
    "                    class_mode = \"categorical\")\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "                    TEST_PATH,\n",
    "                    target_size = (img_height, img_width),\n",
    "                    batch_size = BS,\n",
    "                    shuffle = False,\n",
    "                    class_mode = \"categorical\")\n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "                    TEST_PATH,\n",
    "                    target_size = (img_height, img_width),\n",
    "                    batch_size = BS,\n",
    "                    shuffle = False,\n",
    "                    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# loading pre-trained model, training additional features and saving model\n",
    "base_model = VGG19(weights = \"imagenet\", include_top=False, \n",
    "                   input_shape = (img_width, img_height, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = \"relu\")(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256, activation = \"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "preds = Dense(NB, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(input = base_model.input, output = preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)\n",
    "\n",
    "for layer in model.layers[:16]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[16:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor = 'val_acc', min_delta = 0, \n",
    "                      patience = 10, verbose= 1 , mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", \n",
    "                    optimizer = SGD(lr=0.001, momentum=0.9), \n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit_generator(\n",
    "        trainGen,\n",
    "        epochs = EPOCHS,\n",
    "        steps_per_epoch = TRAIN // BS,\n",
    "        validation_data = valGen,\n",
    "        validation_steps = VAL // BS,\n",
    "        callbacks = [early])\n",
    "\n",
    "model.save('4_3_Model_Binary_Transfer_kjaisingh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating predictions using model\n",
    "testGen.reset()\n",
    "predictions = model.predict_generator(testGen, steps = (TEST // BS) + 1) \n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Test set accuracy: \" + \n",
    "      str(accuracy_score(testGen.classes, predictions, normalize=True) * 100) \n",
    "      + \"%\") \n",
    "\n",
    "print(classification_report(testGen.classes, predictions,\n",
    "                            target_names=testGen.class_indices.keys())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting training data\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
