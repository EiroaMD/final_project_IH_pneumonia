{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclassification with pre-established folders (flow from directory method) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to build a Convolutional Neural Network using the `flow_from_directory` method for three classes:\n",
    "    - Normal\n",
    "    - Not-notmal/Not-pneumonia\n",
    "    - Pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# System and file management\n",
    "import os\n",
    "import zipfile\n",
    "from glob import glob\n",
    "\n",
    "# Visualization Tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from skimage.io import imread\n",
    "\n",
    "# Pandas defaults\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "# jupyter:\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container { width:100% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICOM\n",
    "import pydicom\n",
    "from pydicom.filereader import dcmread\n",
    "\n",
    "# SKLEARN\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfolder_creator(path):\n",
    "    \"\"\"\n",
    "    This function checks wether a folder exist. In case it does not, it creates it.\n",
    "    \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        path\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "\n",
    "        \n",
    "        \n",
    "def dcm_to_img(origin_fpath, destination_fpath, PNG=False):\n",
    "    \"\"\"\n",
    "    This function extracts the image information from DICOM (.dcm) files\n",
    "    and converts it to either .png or .jpg files, saving it in the desired folder\n",
    "    Inputs:\n",
    "        - origin_fpath: path where the .dcm files are located.\n",
    "        - destination_fpath: desired output path of the converted images.\n",
    "        - PNG: default False. Wether you want the output files in .png (set as True) or .jpg format.\n",
    "    Outputs:\n",
    "        - Converted files, either to *.png or *.jpg.\n",
    "    \"\"\"\n",
    "    \n",
    "    images_path = os.listdir(origin_fpath) # List of files inside origin folder\n",
    "    \n",
    "    for n, image in enumerate(images_path):\n",
    "        ds = pydicom.dcmread(os.path.join(origin_fpath, image))\n",
    "        pixel_array_numpy = ds.pixel_array\n",
    "        if PNG == False:\n",
    "            image = image.replace('.dcm', '.jpg')\n",
    "        else:\n",
    "            image = image.replace('.dcm', '.png')\n",
    "        cv2.imwrite(os.path.join(destination_fpath, image), pixel_array_numpy)\n",
    "        if n % 1000 == 0:\n",
    "            print('{} images converted'.format(n)) # Counter for every 1000 images converted\n",
    "\n",
    "\n",
    "            \n",
    "def move_files(origin_fpath, destination_fpath, file_list):\n",
    "    \"\"\"\n",
    "    This function checks if the directories exists then moves the files whose names are contained \n",
    "    in the list to the desired destination directory.\n",
    "    Inputs:\n",
    "        - origin_fpath: path of origin of the files.\n",
    "        - destination_fpath: desired destination path.\n",
    "        - file_list: the list of names of the files that are to be moved.\n",
    "    Outputs:\n",
    "        - No outputs displayed.\n",
    "    \"\"\"\n",
    "    # Check if both the are directories\n",
    "    if os.path.isdir(origin_fpath) and os.path.isdir(destination_fpath) :\n",
    "        # Iterate over all the files in a list, that we know are located in the source directory\n",
    "        for file in file_list:\n",
    "            # Define the route:\n",
    "            file_path = os.path.join(origin_fpath, file)\n",
    "            # Move each file to destination Directory\n",
    "            shutil.move(file_path, destination_fpath);\n",
    "    else:\n",
    "        print(\"origin_fpath & destination_fpath should be Directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/' # root\n",
    "CSV_PATH = os.path.join(PATH,'csv') # folder with csv datasets\n",
    "DICOM_PATH = os.path.join(PATH, 'pool') # folder containing all of the dicom files\n",
    "JPG_PATH = os.path.join(PATH, 'pool_jpg') # folder containing all the converted jpg files\n",
    "DESTINATION_PATH = os.path.join(PATH, 'sorted_balanced') # Folder where the train and test subsets will be located\n",
    "MODELS_PATH = os.path.join(PATH,'model')\n",
    "\n",
    "# Train folder\n",
    "TRAIN_PATH = os.path.join(DESTINATION_PATH, 'train')\n",
    "TRAIN_NORMAL_PATH = os.path.join(TRAIN_PATH, 'normal')\n",
    "TRAIN_NNNP_PATH = os.path.join(TRAIN_PATH, 'nnnp')\n",
    "TRAIN_PNEUMONIA_PATH = os.path.join(TRAIN_PATH, 'pneumonia')\n",
    "\n",
    "# Validation folder\n",
    "VAL_PATH = os.path.join(DESTINATION_PATH, 'validation')\n",
    "VAL_NORMAL_PATH = os.path.join(VAL_PATH, 'normal')\n",
    "VAL_NNNP_PATH = os.path.join(VAL_PATH, 'nnnp')\n",
    "VAL_PNEUMONIA_PATH = os.path.join(VAL_PATH, 'pneumonia')\n",
    "\n",
    "# Test folder\n",
    "TEST_PATH = os.path.join(DESTINATION_PATH, 'test')\n",
    "TEST_NORMAL_PATH = os.path.join(TEST_PATH, 'normal') \n",
    "TEST_NNNP_PATH = os.path.join(TEST_PATH, 'nnnp')\n",
    "TEST_PNEUMONIA_PATH = os.path.join(TEST_PATH, 'pneumonia') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = pd.read_csv(os.path.join(CSV_PATH, 'balanced_cxr_information.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns which contain the output:\n",
    "columns = ['type_0', 'type_1', 'type_2']\n",
    "\n",
    "# Batch size:\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "IMAGE_SIZE = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_PATH,  # This is the source directory for training images\n",
    "        target_size=(512, 512),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "        VAL_PATH,  # This is the source directory for training images\n",
    "        target_size=(512, 512),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using val_datagen generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_PATH,\n",
    "        target_size=(512, 512),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input feature map is 512x512x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "img_input = layers.Input(shape=(512, 512, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "# max-pooling is followed by a dropout to try to avoid overfitting\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "# max-pooling is followed by a dropout to try to avoid overfitting\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "# max-pooling is followed by a dropout to try to avoid overfitting\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Dropout(0.25)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Create output layer with a single node and sigmoid activation\n",
    "output = layers.Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "# Create model:\n",
    "# input = input feature map\n",
    "# output = input feature map + stacked convolution/maxpooling layers + fully \n",
    "# connected layer + sigmoid output layer\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tensorflow.compat.v2.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting constants: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VAL = val_generator.n//val_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VAL,\n",
    "                    epochs=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"3_class_flow_dir_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"3_class_flow_dir_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred >0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pred_bool.astype(int)\n",
    "columns = columns\n",
    "#columns should be the same order of y_col\n",
    "results=pd.DataFrame(predictions, columns=columns)\n",
    "results[\"Filenames\"]=test_generator.filenames\n",
    "ordered_cols=[\"Filenames\"]+columns\n",
    "results=results[ordered_cols]#To get the same column order\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "#Confusion Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(val_generator, STEP_SIZE_VAL)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(val_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Normal', 'NNNP', 'Pneumonia']\n",
    "print(classification_report(val_generator.classes, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
